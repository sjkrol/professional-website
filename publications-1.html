<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dr. Stephen James Krol - Academic Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="header-content">
            <div class="header-text">
                <h1>Dr. Stephen James Krol</h1>
                <p class="subtitle">Research Fellow in Machine Learning</p>
                <nav>
                    <a href="./index.html">About</a>
                    <a href="./research.html">Research</a>
                    <a href="./publications-1.html" class="active">Publications</a>
                    <a href="./teaching.html">Teaching</a>
                    <a href="./index.html#contact">Contact</a>
                </nav>
            </div>
            <img src="./images/profile_picture.jpeg" alt="Dr. Stephen James Krol" class="profile-pic">
        </div>
    </header>
    <div class="container">
        <section id="publications">
            <h2>All Publications</h2>
            <!-- <p>Click on a publication venue to reveal the abstract. Click on the title to view the full paper.</p> -->
            <div class="publication">
                <h3>
                    <a href="https://openreview.net/forum?id=k9HOf7NBLp" target="_blank">Supporting Creative Ownership through Deep Learning-Based Music Variation</a>
                </h3>
                <p class="authors"><strong>Stephen James Krol</strong>, Maria Teresa Llano, Jon McCormack</p>
                <p class="venue">NeurIPS Creative AI Track 2025</p>

                <!-- Hidden abstract -->
                <div class="abstract">
                    <p>
                        This paper investigates the importance of personal ownership in musical AI design, examining how practising musicians can maintain creative control over the compositional process.
                        Through a four-week ecological evaluation, we examined how a music variation tool, reliant on the skill of musicians, functioned within a composition setting. Our findings demonstrate
                        that the dependence of the tool on the musician's ability, to provide a strong initial musical input and to turn moments into complete musical ideas, promoted ownership of both the process
                        and artefact. Qualitative interviews further revealed the importance of this personal ownership, highlighting tensions between technological capability and artistic identity. These
                        findings provide insight into how musical AI can support rather than replace human creativity, highlighting the importance of designing tools that preserve the humanness of musical expression.
                    </p>
                </div>
            </div>

            <div class="publication">
                <h3><a href="https://dl.acm.org/doi/full/10.1145/3706598.3713894" target="_blank">Exploring the Needs of Practising Musicians in Co-Creative AI Through Co-Design</a></h3>
                <p class="authors"><strong>Stephen James Krol</strong>, Maria Teresa Llano, Miguel Loor Paredes</p>
                <p class="venue">CHI Conference on Human Factors in Computing Systems 2025</p>
                <div class="abstract">
                    <p>
                    Recent advances in generative AI music have resulted in new technologies that are being framed as co-creative tools for musicians with early work demonstrating their potential to add to music practice. 
                    While the field has seen many valuable contributions, work that involves practising musicians in the design and development of these tools is limited, with the majority of work including them only once 
                    a tool has been developed. In this paper, we present a case study that explores the needs of practising musicians through the co-design of a musical variation system, highlighting the importance of
                    involving a diverse range of musicians throughout the design process and uncovering various design insights. This was achieved through two workshops and a two week ecological evaluation, where musicians
                    from different musical backgrounds offered valuable insights not only on a musical system’s design but also on how a musical AI could be integrated into their musical practices.
                    </p>
                </div>
            </div>

            <div class="publication">
                <h3><a href="https://ceur-ws.org/Vol-3810/paper3.pdf" target="_blank">From Simple to Complex: Extending the Generative Capabilities of Attribute-Based Latent Space Regularization through AR-VAE-Diffusion</a></h3>
                <p class="authors"><strong>Stephen James Krol</strong>, Abhinav Sood, Maria Teresa Llano</p>
                <p class="venue">CREAI 2024 Workshop at ECAI 2024</p>
                <div class="abstract">
                    <p>
                    Progress in deep learning has driven the development of diverse creativity support tools (CST) capable of
                    producing a range of creative artefacts. However, deep generative models are not inherently controllable,
                    posing challenges in their guidance and prompting research focused on incorporating control mechanisms
                    into models. One such method, Attribute-Based Latent Space Regularisation (ALSR), has demonstrated
                    notable controllability when implemented within an Attribute-Regularised Variational Autoencoder
                    (AR-VAE) for music and simple image generation. However, ALSR’s effectiveness is constrained by the
                    generative capabilities of the AR-VAE and is unable to control generations for high-fidelity images. In
                    this work, we add a Denoising Diffusion Probabilistic Model (DDPM) to the AR-VAE and demonstrate
                    that the resulting AR-VAE-Diffusion model is capable of generating and controlling high fidelity images,
                    thus broadening the applicability of ALSR and providing a new pathway for introducing controllability
                    into future deep learning CSTs.
                    </p>
                </div>
            </div>

            <div class="publication">
                <h3><a href="https://computationalcreativity.net/iccc24/papers/ICCC24_paper_103.pdf" target="_blank">Design Considerations for Automatic Musical Soundscapes of Visual Art for People with Blindeness or Low Vision</a></h3>
                <p class="authors"><strong>Stephen James Krol</strong>, Maria Teresa Llano, Matthew Butler, Cagatay Goncu</p>
                <p class="venue">International Conference on Computational Creativity 2024</p>
                <div class="abstract">
                    <p>
                    Music has been identified as a promising medium to enhance
                    the accessibility and experience of visual art for people who
                    are blind or have low vision (BLV). However, composing
                    music and designing soundscapes for visual art is a timeconsuming, resource intensive process - limiting its scalability for large exhibitions. In this paper, we investigate the use
                    of automated soundscapes to increase the accessibility of visual art. We built a prototype system and ran a qualitative
                    study to evaluate the aesthetic experience provided by the
                    automated soundscapes with 10 BLV participants. From the
                    study, we identified a set of design considerations that reveal
                    requirements from BLV people for the development of automated soundscape systems, setting new directions in which
                    creative systems could enrich the aesthetic experience conveyed by these.
                    </p>
                </div>
            </div>

            <div class="publication">
                <h3><a href="https://link.springer.com/chapter/10.1007/978-3-031-56992-0_18" target="_blank">No Longer Trending on Artstation: Prompt Analysis of Generative AI Art</a></h3>
                <p class="authors">Jon McCormack, Maria Teresa Llano, <strong>Stephen James Krol</strong>, Nina Rajcic</p>
                <p class="venue">International Conference on Computational Intelligence in Music, Sound, Art and Design EvoMUSART 2024</p>
                <div class="abstract">
                    <p>
                    Image generation using generative AI is rapidly becoming
                    a major new source of visual media, with billions of AI generated images created using diffusion models such as Stable Diffusion and Midjourney over the last few years. In this paper we collect and analyse
                    over 3 million prompts and the images they generate. Using natural language processing, topic analysis and visualisation methods we aim to
                    understand collectively how people are using text prompts, the impact
                    of these systems on artists, and more broadly on the visual cultures they
                    promote. Our study shows that prompting focuses largely on surface aesthetics, reinforcing cultural norms, popular conventional representations
                    and imagery. We also find that many users focus on popular topics (such
                    as making colouring books, fantasy art, or Christmas cards), suggesting
                    that the dominant use for the systems analysed is recreational rather
                    than artistic.
                    </p> 
                </div>   
            </div>
        </section>
    </div>

    <!-- Pagination placeholder -->
    <nav class="pagination" id="pagination"></nav>
</body>
<script src="publications.js"></script>
<script>
    createPagination('pagination', 1, 2, 'publications-{page}.html');
</script>